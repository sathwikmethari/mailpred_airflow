{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4f6dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu129\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import os, torch, umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from dags.utils.gm_main_utils import get_embeddings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dags.utils.gm_data_utils import decode_zip, extract_headers, decode_body\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available()) \n",
    "# load_dotenv()\n",
    "# # SCOPES: Gmail read-only\n",
    "# SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "# token_path = os.getenv(\"token_path\")\n",
    "# credentials_path = os.getenv(\"credentials_path\")\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1da765",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = \"data/imp_22-08-2025-03-23.json.gz\"\n",
    "path_2 = \"data/unimp_22-08-2025-03-23.json.gz\"\n",
    "path_3 = \"data/15-08-2025-10-41.json.gz\"\n",
    "\n",
    "decompressed_data_1 = decode_zip(path_1)\n",
    "decompressed_data_2 = decode_zip(path_2)\n",
    "decompressed_data_3 = decode_zip(path_3)\n",
    "\n",
    "df_imp =pd.DataFrame(decompressed_data_1)[[\"Payload\"]]\n",
    "df_unimp =pd.DataFrame(decompressed_data_2)[[\"Payload\"]]\n",
    "df_unlb =pd.DataFrame(decompressed_data_3)[[\"Payload\"]]\n",
    "\n",
    "df_imp[\"Subject\"] = df_imp[\"Payload\"].apply(extract_headers)\n",
    "df_imp[\"Body\"] = df_imp[\"Payload\"].apply(decode_body)\n",
    "df_imp[\"Important\"] = 1\n",
    "df_imp = df_imp.drop([\"Payload\"], axis=1)\n",
    "\n",
    "df_unimp[\"Subject\"] = df_unimp[\"Payload\"].apply(extract_headers)\n",
    "df_unimp[\"Body\"] = df_unimp[\"Payload\"].apply(decode_body)\n",
    "df_unimp[\"Important\"] = 0\n",
    "df_unimp = df_unimp.drop([\"Payload\"], axis=1)\n",
    "\n",
    "df_unlb[\"Subject\"] = df_unlb[\"Payload\"].apply(extract_headers)\n",
    "df_unlb[\"Body\"] = df_unlb[\"Payload\"].apply(decode_body)\n",
    "df_unlb = df_unlb.drop([\"Payload\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5890c64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject       0\n",
       "Body         53\n",
       "Important     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([df_imp, df_unimp])\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c3c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Body\"] = train[\"Body\"].fillna(train[\"Subject\"]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a8f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_embeddings(train, model_name)\n",
    "y = torch.from_numpy(train.loc[:,\"Important\"].values)\n",
    "#y = train.loc[:,\"Important\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122a22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15bd6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "def objective2(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 5.0),\n",
    "        \"objective\": \"binary:logistic\", \n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "    \n",
    "\n",
    "    cls = xgb.train(params, dtrain, num_boost_round = 1500)    \n",
    "    y_pred_proba = cls.predict(dtest)\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    # Decrease threshold for negating False Negatives\n",
    "    y_pred_binary = (y_pred_proba > 0.50).astype(int)\n",
    "    \n",
    "    score = recall_score(y_test, y_pred_binary)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64858d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 18:29:31,521] A new study created in memory with name: no-name-879713b3-10ce-4fa8-a31a-1d3f899f9a9a\n",
      "[I 2025-08-24 18:29:33,843] Trial 0 finished with value: 0.85 and parameters: {'max_depth': 10, 'eta': 0.2953843525095601, 'subsample': 0.9911081873116594, 'colsample_bytree': 0.56475886114318, 'gamma': 4.142897505182672, 'reg_alpha': 2.522754984354045, 'reg_lambda': 3.9680792319066267}. Best is trial 0 with value: 0.85.\n",
      "[I 2025-08-24 18:29:36,675] Trial 1 finished with value: 0.85 and parameters: {'max_depth': 5, 'eta': 0.17607660681500664, 'subsample': 0.810958297859574, 'colsample_bytree': 0.7117333075391337, 'gamma': 0.1796378705140883, 'reg_alpha': 3.146550622924668, 'reg_lambda': 0.5959542185077749}. Best is trial 0 with value: 0.85.\n",
      "[I 2025-08-24 18:29:38,680] Trial 2 finished with value: 0.9 and parameters: {'max_depth': 3, 'eta': 0.18954892595276174, 'subsample': 0.6464215011544552, 'colsample_bytree': 0.8140873451467547, 'gamma': 2.662248008680188, 'reg_alpha': 1.2519909063953427, 'reg_lambda': 3.401369416498599}. Best is trial 2 with value: 0.9.\n",
      "[I 2025-08-24 18:29:41,203] Trial 3 finished with value: 0.9 and parameters: {'max_depth': 12, 'eta': 0.13376119953034046, 'subsample': 0.8225323579358137, 'colsample_bytree': 0.9739488685892397, 'gamma': 4.624914561350629, 'reg_alpha': 2.548669314603342, 'reg_lambda': 1.2997702271922278}. Best is trial 2 with value: 0.9.\n",
      "[I 2025-08-24 18:29:43,660] Trial 4 finished with value: 0.875 and parameters: {'max_depth': 5, 'eta': 0.2821431229378649, 'subsample': 0.854560383554164, 'colsample_bytree': 0.5125172895787502, 'gamma': 1.3999068964772454, 'reg_alpha': 1.6945252163064506, 'reg_lambda': 0.5417467881296323}. Best is trial 2 with value: 0.9.\n",
      "[I 2025-08-24 18:29:45,815] Trial 5 finished with value: 0.9 and parameters: {'max_depth': 11, 'eta': 0.26505557158484766, 'subsample': 0.5507654305069959, 'colsample_bytree': 0.7189413743719569, 'gamma': 2.757320746795137, 'reg_alpha': 3.1303478470410133, 'reg_lambda': 3.2655806508739964}. Best is trial 2 with value: 0.9.\n",
      "[I 2025-08-24 18:29:48,513] Trial 6 finished with value: 0.9 and parameters: {'max_depth': 13, 'eta': 0.1038851590495999, 'subsample': 0.7085410300405071, 'colsample_bytree': 0.5131337365597123, 'gamma': 0.47863925393252627, 'reg_alpha': 1.484907976152849, 'reg_lambda': 3.2015000728397562}. Best is trial 2 with value: 0.9.\n",
      "[I 2025-08-24 18:29:50,509] Trial 7 finished with value: 0.85 and parameters: {'max_depth': 3, 'eta': 0.24021982576703985, 'subsample': 0.6392919417470203, 'colsample_bytree': 0.8409382482039645, 'gamma': 1.177263531517656, 'reg_alpha': 1.9559154634305198, 'reg_lambda': 1.4244140681034378}. Best is trial 2 with value: 0.9.\n",
      "[I 2025-08-24 18:29:53,579] Trial 8 finished with value: 0.875 and parameters: {'max_depth': 13, 'eta': 0.02364867318937693, 'subsample': 0.9631495596252433, 'colsample_bytree': 0.7973758565104778, 'gamma': 4.0058744999795755, 'reg_alpha': 3.8375520039906954, 'reg_lambda': 2.457716334100491}. Best is trial 2 with value: 0.9.\n",
      "[I 2025-08-24 18:29:55,495] Trial 9 finished with value: 0.9 and parameters: {'max_depth': 3, 'eta': 0.1602494392940082, 'subsample': 0.5189300514077239, 'colsample_bytree': 0.7656521897411888, 'gamma': 2.5512080562896995, 'reg_alpha': 4.7938206652856605, 'reg_lambda': 0.6000699920746377}. Best is trial 2 with value: 0.9.\n",
      "[I 2025-08-24 18:29:57,832] Trial 10 finished with value: 0.925 and parameters: {'max_depth': 8, 'eta': 0.2065724597852113, 'subsample': 0.6252108412049208, 'colsample_bytree': 0.9216133802246547, 'gamma': 3.168417267063779, 'reg_alpha': 0.4285724762610946, 'reg_lambda': 4.706322521262264}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:00,125] Trial 11 finished with value: 0.875 and parameters: {'max_depth': 8, 'eta': 0.20034320637014086, 'subsample': 0.6474931639996384, 'colsample_bytree': 0.9342098192693469, 'gamma': 3.3284942445340975, 'reg_alpha': 0.05482039636179936, 'reg_lambda': 4.877320024000596}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:02,455] Trial 12 finished with value: 0.9 and parameters: {'max_depth': 8, 'eta': 0.21820268508942456, 'subsample': 0.6174854944614402, 'colsample_bytree': 0.8915330121385611, 'gamma': 1.816928149401574, 'reg_alpha': 0.3698579893856831, 'reg_lambda': 4.942095701151164}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:05,360] Trial 13 finished with value: 0.9 and parameters: {'max_depth': 6, 'eta': 0.09650620423260428, 'subsample': 0.7133267643423564, 'colsample_bytree': 0.881580673611702, 'gamma': 3.2643990416302655, 'reg_alpha': 0.7962941673767941, 'reg_lambda': 4.024616435554708}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:07,824] Trial 14 finished with value: 0.875 and parameters: {'max_depth': 7, 'eta': 0.19947164759977917, 'subsample': 0.5800757496543183, 'colsample_bytree': 0.9946321364976487, 'gamma': 2.0363988607491823, 'reg_alpha': 0.9825387659683161, 'reg_lambda': 3.9008972588870803}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:10,421] Trial 15 finished with value: 0.875 and parameters: {'max_depth': 15, 'eta': 0.23713533823450889, 'subsample': 0.7555110682090636, 'colsample_bytree': 0.6540773018089295, 'gamma': 3.327724173504299, 'reg_alpha': 1.0866726421496722, 'reg_lambda': 2.506277270083901}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:12,697] Trial 16 finished with value: 0.9 and parameters: {'max_depth': 9, 'eta': 0.12425861683574677, 'subsample': 0.6713007606517303, 'colsample_bytree': 0.8298767364961532, 'gamma': 4.976726888497567, 'reg_alpha': 0.4830728451917944, 'reg_lambda': 4.360888824509882}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:15,369] Trial 17 finished with value: 0.9 and parameters: {'max_depth': 4, 'eta': 0.0636305152378229, 'subsample': 0.505551878027168, 'colsample_bytree': 0.9155729049304383, 'gamma': 2.950506109259308, 'reg_alpha': 1.2942405663761818, 'reg_lambda': 3.2323087030603346}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:17,525] Trial 18 finished with value: 0.85 and parameters: {'max_depth': 6, 'eta': 0.17935608556270094, 'subsample': 0.5896818262152352, 'colsample_bytree': 0.6491789642114578, 'gamma': 2.1551431899981788, 'reg_alpha': 2.0161119551787277, 'reg_lambda': 2.639785822139926}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:19,779] Trial 19 finished with value: 0.925 and parameters: {'max_depth': 9, 'eta': 0.24878771786748802, 'subsample': 0.7203983337383106, 'colsample_bytree': 0.8441463858532118, 'gamma': 3.920616742089755, 'reg_alpha': 0.08194588750703619, 'reg_lambda': 4.3920576132821605}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:22,218] Trial 20 finished with value: 0.875 and parameters: {'max_depth': 10, 'eta': 0.25974860553253126, 'subsample': 0.7471042184684473, 'colsample_bytree': 0.9433686725491411, 'gamma': 3.8646746781075803, 'reg_alpha': 0.5099726916069145, 'reg_lambda': 4.562741220797303}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:24,448] Trial 21 finished with value: 0.9 and parameters: {'max_depth': 8, 'eta': 0.2242327410611789, 'subsample': 0.6854258378363172, 'colsample_bytree': 0.8367168817097058, 'gamma': 3.6213264628162616, 'reg_alpha': 0.01762756491199058, 'reg_lambda': 3.608438204302975}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:26,845] Trial 22 finished with value: 0.85 and parameters: {'max_depth': 7, 'eta': 0.19730326341125115, 'subsample': 0.7682044849365389, 'colsample_bytree': 0.8679042039342406, 'gamma': 4.302729615811415, 'reg_alpha': 0.8149759619377022, 'reg_lambda': 4.4325747065027326}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:28,997] Trial 23 finished with value: 0.875 and parameters: {'max_depth': 10, 'eta': 0.256168204946308, 'subsample': 0.588866882626129, 'colsample_bytree': 0.7776603188154338, 'gamma': 3.0726055479918934, 'reg_alpha': 0.007157901115043275, 'reg_lambda': 3.6768911181555715}. Best is trial 10 with value: 0.925.\n",
      "[I 2025-08-24 18:30:31,903] Trial 24 finished with value: 0.9 and parameters: {'max_depth': 9, 'eta': 0.15379610846267014, 'subsample': 0.9046577101989605, 'colsample_bytree': 0.8064433146943104, 'gamma': 2.400137686151451, 'reg_alpha': 0.5269743646807493, 'reg_lambda': 4.394432733761879}. Best is trial 10 with value: 0.925.\n"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective2, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5185f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UMAP reduction to 2D\n",
    "# umap_model = umap.UMAP(n_neighbors=10, min_dist=0.3, random_state=42, n_components=2)\n",
    "# emb_2d = umap_model.fit_transform(embeddings)\n",
    "\n",
    "# # Some Overlap is expected\n",
    "# #High-dimensional separation may not be visible in 2d\n",
    "# #Can try diff embedding/tokenizer\n",
    "\n",
    "\n",
    "# # Scatterplot\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# scatter = plt.scatter(emb_2d[:, 0], emb_2d[:, 1], c=labels, cmap=\"Spectral\", alpha=0.8)\n",
    "# plt.xlabel(\"UMAP-1\")\n",
    "# plt.ylabel(\"UMAP-2\")\n",
    "# plt.title(\"Sentence Embeddings with UMAP (colored by label)\")\n",
    "# plt.colorbar(scatter, label=\"Dependent Variable (0/1)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4203a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = \"\"\n",
    "body = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e2a16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2 = pd.DataFrame({\n",
    "#     \"Subject\": [sub],\n",
    "#     \"Body\":[body]\n",
    "# })\n",
    "\n",
    "# embeddings_2 =get_embeddings(df_2, model_name)\n",
    "\n",
    "# dunlabeled_2 = xgb.DMatrix(embeddings_2)\n",
    "# y_pred_proba_2 = model.predict(dunlabeled_2)\n",
    "# print(y_pred_proba_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41fa8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlb_embeddings = get_embeddings(df_unlb, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "186469fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "thresh = 0.95\n",
    "\n",
    "\n",
    "optuna_params = study.best_trial.params\n",
    "\n",
    "X_c, y_c = X_train.clone(), y_train.clone()\n",
    "X_unlb = unlb_embeddings.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec6b6fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>Epoch 1<<<<\n",
      "Added 60 pseudo samples. Labeled samples size: 291\n",
      "\n",
      ">>>>Epoch 2<<<<\n",
      "Added 3 pseudo samples. Labeled samples size: 294\n",
      "\n",
      ">>>>Epoch 3<<<<\n",
      "Added 36 pseudo samples. Labeled samples size: 330\n",
      "\n",
      ">>>>Epoch 4<<<<\n",
      "No high-confidence samples found.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,epochs):\n",
    "    print(f\"\\n>>>>Epoch {epoch}<<<<\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_c, label=y_c)\n",
    "    model = xgb.train(optuna_params, dtrain, num_boost_round=1500)\n",
    "\n",
    "    if len(X_unlb) == 0:\n",
    "        print(\"No unlabeled data left.\")\n",
    "        break\n",
    "\n",
    "    d_unlb = xgb.DMatrix(X_unlb)\n",
    "    y_proba = model.predict(d_unlb)\n",
    "    y_proba = torch.from_numpy(y_proba)\n",
    "\n",
    "    mask = (y_proba > thresh) | (y_proba < 1 - thresh) # a tensor of True, False... of shape y_proba\n",
    "    \n",
    "    if mask.sum() == 0:                                # True==1, False==0\n",
    "        print(\"No high-confidence samples found.\")\n",
    "        break\n",
    "\n",
    "    X_pseudo = X_unlb[mask]\n",
    "    y_pseudo = (y_proba[mask] > 0.5).int() # torch.int\n",
    "\n",
    "    # move high confidence rows from unlabeled to training set\n",
    "    X_c = torch.vstack([X_c, X_pseudo]) # stacks vertically. similar to 1d append but for high d's. \n",
    "    y_c = torch.cat([y_c, y_pseudo], axis =0)\n",
    "\n",
    "    # Remove high confidence rows\n",
    "    X_unlb = X_unlb[~mask]\n",
    "\n",
    "    print(f\"Added {len(X_pseudo)} pseudo samples. Labeled samples size: {len(y_c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62d55446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model\n",
    "dfinal = xgb.DMatrix(X_c, label=y_c)\n",
    "final_model = xgb.train(optuna_params, dfinal, num_boost_round=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81d21fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  5]\n",
      " [ 4 36]]\n"
     ]
    }
   ],
   "source": [
    "dunlabeled = xgb.DMatrix(X_test)\n",
    "y_pred_proba = final_model.predict(dunlabeled)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "# Decrease threshold for negating False Negatives\n",
    "y_pred_binary = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm =confusion_matrix(y_test, y_pred_binary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d664337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f67b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save_model(\"data/XGBmodel.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow-docker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
