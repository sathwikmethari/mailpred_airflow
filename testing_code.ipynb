{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c4f6dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu130\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch, umap, optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from dags.utils.embedding_utils import get_embeddings\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "from dags.utils.encode_utils import decode_zip\n",
    "from dags.utils.payload_utils import decode_gmail_payload\n",
    "\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available()) \n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1da765",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = \"data/imp_22-08-2025-03-23.json.gz\"\n",
    "path_2 = \"data/unimp_22-08-2025-03-23.json.gz\"\n",
    "path_3 = \"data/15-08-2025-10-41.json.gz\"\n",
    "\n",
    "decompressed_data_1 = decode_zip(path_1)\n",
    "decompressed_data_2 = decode_zip(path_2)\n",
    "decompressed_data_3 = decode_zip(path_3)\n",
    "\n",
    "df_imp =pd.DataFrame(decompressed_data_1)[[\"Payload\"]]\n",
    "df_unimp =pd.DataFrame(decompressed_data_2)[[\"Payload\"]]\n",
    "df_unlb =pd.DataFrame(decompressed_data_3)[[\"Payload\"]]\n",
    "\n",
    "df_imp[[\"Subject\", \"Body\"]] = df_imp[\"Payload\"].apply(lambda row: pd.Series(decode_gmail_payload(row)[1:]))\n",
    "df_imp[\"Important\"] = 1\n",
    "df_imp = df_imp.drop([\"Payload\"], axis=1) \n",
    "\n",
    "df_unimp[[\"Subject\", \"Body\"]] = df_unimp[\"Payload\"].apply(lambda row: pd.Series(decode_gmail_payload(row)[1:]))\n",
    "df_unimp[\"Important\"] = 0\n",
    "df_unimp = df_unimp.drop([\"Payload\"], axis=1)\n",
    "\n",
    "df_unlb[[\"Subject\", \"Body\"]] = df_unlb[\"Payload\"].apply(lambda row: pd.Series(decode_gmail_payload(row))[1:])\n",
    "df_unlb = df_unlb.drop([\"Payload\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5890c64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject      0\n",
       "Body         0\n",
       "Important    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([df_imp, df_unimp])\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76a8f7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X = get_embeddings(train, model_name, device)\n",
    "print(X.get_device())\n",
    "y = torch.from_numpy(train.loc[:,\"Important\"].values).cuda()\n",
    "#y = train.loc[:,\"Important\"].values\n",
    "print(y.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24ceca31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b465a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15bd6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_test_np = y_test.cpu().numpy()\n",
    "\n",
    "default_params = {\n",
    "        \"objective\": \"binary:logistic\", \n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"random_state\": 42,\n",
    "}\n",
    "def objective2(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 5.0),\n",
    "        **default_params\n",
    "    }\n",
    "    \n",
    "\n",
    "    cls = xgb.train(params, dtrain, num_boost_round = 1500)    \n",
    "    y_pred_proba = cls.predict(dtest)\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred_binary = (y_pred_proba > 0.50).astype(int)\n",
    "    \n",
    "    score = recall_score(y_test_np, y_pred_binary)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64858d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 18:06:53,909] A new study created in memory with name: no-name-f5674152-3a6f-4606-b771-ec04a329e41b\n",
      "[I 2025-11-06 18:07:04,469] Trial 0 finished with value: 0.825 and parameters: {'max_depth': 7, 'eta': 0.24607036723951145, 'subsample': 0.8894990870083058, 'colsample_bytree': 0.6933244850450013, 'gamma': 3.9838266759264696, 'reg_alpha': 1.0375946750319154, 'reg_lambda': 1.8274508970284042}. Best is trial 0 with value: 0.825.\n",
      "[I 2025-11-06 18:07:04,637] Trial 2 finished with value: 0.875 and parameters: {'max_depth': 14, 'eta': 0.2071210797444219, 'subsample': 0.656157184698971, 'colsample_bytree': 0.8822217787577966, 'gamma': 1.8297526409683207, 'reg_alpha': 1.6852872146236737, 'reg_lambda': 4.058797840407122}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:04,832] Trial 1 finished with value: 0.85 and parameters: {'max_depth': 11, 'eta': 0.07777390595505697, 'subsample': 0.8729439534923629, 'colsample_bytree': 0.9997651028620271, 'gamma': 1.3299048697721965, 'reg_alpha': 3.0251386077717397, 'reg_lambda': 1.4236440745303076}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:06,534] Trial 3 finished with value: 0.8 and parameters: {'max_depth': 11, 'eta': 0.14399142770845488, 'subsample': 0.6078928851857566, 'colsample_bytree': 0.983304564375894, 'gamma': 1.4226441143744972, 'reg_alpha': 2.335043470095324, 'reg_lambda': 0.6928716309170702}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:06,848] Trial 4 finished with value: 0.85 and parameters: {'max_depth': 4, 'eta': 0.02446310992863492, 'subsample': 0.5538240692699243, 'colsample_bytree': 0.584449432413221, 'gamma': 3.2329068562123027, 'reg_alpha': 3.913327314982331, 'reg_lambda': 4.036019007352033}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:15,035] Trial 6 finished with value: 0.875 and parameters: {'max_depth': 8, 'eta': 0.2606007346311881, 'subsample': 0.5940650034321519, 'colsample_bytree': 0.6744541170752338, 'gamma': 3.8906005350530046, 'reg_alpha': 1.227117598435059, 'reg_lambda': 2.2040466927904805}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:15,165] Trial 7 finished with value: 0.875 and parameters: {'max_depth': 3, 'eta': 0.16860804166175794, 'subsample': 0.8629767474590243, 'colsample_bytree': 0.909413800553551, 'gamma': 3.0619208718260795, 'reg_alpha': 1.186110759669829, 'reg_lambda': 4.953213372488695}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:15,568] Trial 5 finished with value: 0.825 and parameters: {'max_depth': 5, 'eta': 0.023703463495004844, 'subsample': 0.956230960692017, 'colsample_bytree': 0.8408598064237036, 'gamma': 0.9767256541535474, 'reg_alpha': 4.771244331710476, 'reg_lambda': 1.7453895926194207}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:16,379] Trial 9 finished with value: 0.875 and parameters: {'max_depth': 8, 'eta': 0.2630963862835474, 'subsample': 0.8647128322892701, 'colsample_bytree': 0.703446172063015, 'gamma': 1.6737537264926479, 'reg_alpha': 1.3581313872025298, 'reg_lambda': 2.648839109376864}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:16,914] Trial 8 finished with value: 0.85 and parameters: {'max_depth': 3, 'eta': 0.18452716403775796, 'subsample': 0.6309082316453449, 'colsample_bytree': 0.7363302972671126, 'gamma': 4.4482552897447505, 'reg_alpha': 0.28069883849041244, 'reg_lambda': 0.2351397303021857}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:25,014] Trial 11 finished with value: 0.825 and parameters: {'max_depth': 3, 'eta': 0.22791836219901446, 'subsample': 0.5219109660487745, 'colsample_bytree': 0.8553652469887304, 'gamma': 3.979908300140776, 'reg_alpha': 2.0365697725958714, 'reg_lambda': 2.1082204062158656}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:25,198] Trial 12 finished with value: 0.775 and parameters: {'max_depth': 13, 'eta': 0.11891578306329828, 'subsample': 0.8687288219312275, 'colsample_bytree': 0.8772302629703188, 'gamma': 4.779890130085159, 'reg_alpha': 4.359783303654666, 'reg_lambda': 4.996720481225664}. Best is trial 2 with value: 0.875.\n",
      "[I 2025-11-06 18:07:25,213] Trial 10 finished with value: 0.9 and parameters: {'max_depth': 10, 'eta': 0.09582705388516788, 'subsample': 0.6786648082552554, 'colsample_bytree': 0.7663086662587736, 'gamma': 1.9268100047988101, 'reg_alpha': 2.07027376504503, 'reg_lambda': 3.9975262780258265}. Best is trial 10 with value: 0.9.\n",
      "[I 2025-11-06 18:07:27,992] Trial 13 finished with value: 0.875 and parameters: {'max_depth': 4, 'eta': 0.046610474287172174, 'subsample': 0.5652280758611457, 'colsample_bytree': 0.5648673839923205, 'gamma': 2.4961734796843715, 'reg_alpha': 0.7634541188656913, 'reg_lambda': 1.2129138977854037}. Best is trial 10 with value: 0.9.\n",
      "[I 2025-11-06 18:07:28,835] Trial 14 finished with value: 0.9 and parameters: {'max_depth': 14, 'eta': 0.2989491108062191, 'subsample': 0.717581088567094, 'colsample_bytree': 0.8338926433782233, 'gamma': 0.1761878224260176, 'reg_alpha': 2.6050024482207044, 'reg_lambda': 3.3704110887821437}. Best is trial 10 with value: 0.9.\n",
      "[I 2025-11-06 18:07:36,222] Trial 16 finished with value: 0.85 and parameters: {'max_depth': 15, 'eta': 0.2907612053206135, 'subsample': 0.7164627406702061, 'colsample_bytree': 0.5896628140138017, 'gamma': 2.376342611767681, 'reg_alpha': 0.10735310214260574, 'reg_lambda': 3.2031199093491622}. Best is trial 10 with value: 0.9.\n",
      "[I 2025-11-06 18:07:36,317] Trial 15 finished with value: 0.925 and parameters: {'max_depth': 15, 'eta': 0.29413005895258054, 'subsample': 0.7010058837779543, 'colsample_bytree': 0.5504587344415296, 'gamma': 2.390112101741413, 'reg_alpha': 0.19112323744984883, 'reg_lambda': 3.289991856766714}. Best is trial 15 with value: 0.925.\n",
      "[I 2025-11-06 18:07:37,633] Trial 17 finished with value: 0.9 and parameters: {'max_depth': 15, 'eta': 0.08802413057833562, 'subsample': 0.7090282343081773, 'colsample_bytree': 0.776702883605264, 'gamma': 0.020044623737449196, 'reg_alpha': 3.0680161333091553, 'reg_lambda': 3.4826681658560203}. Best is trial 15 with value: 0.925.\n",
      "[I 2025-11-06 18:07:39,845] Trial 18 finished with value: 0.9 and parameters: {'max_depth': 15, 'eta': 0.09972123862183291, 'subsample': 0.7099903394135065, 'colsample_bytree': 0.7874150663003807, 'gamma': 0.00012429283988257822, 'reg_alpha': 3.171176603435975, 'reg_lambda': 3.1374175782142077}. Best is trial 15 with value: 0.925.\n",
      "[I 2025-11-06 18:07:40,620] Trial 19 finished with value: 0.85 and parameters: {'max_depth': 15, 'eta': 0.289570311251263, 'subsample': 0.715199949969801, 'colsample_bytree': 0.7915599118659865, 'gamma': 0.07169820028058217, 'reg_alpha': 3.1107549757068607, 'reg_lambda': 3.1475755100034517}. Best is trial 15 with value: 0.925.\n",
      "[I 2025-11-06 18:07:46,974] Trial 20 finished with value: 0.875 and parameters: {'max_depth': 11, 'eta': 0.10133544308832694, 'subsample': 0.7612847706393011, 'colsample_bytree': 0.7946963294218422, 'gamma': 0.06466792673070776, 'reg_alpha': 3.019597815482604, 'reg_lambda': 3.3860350287882452}. Best is trial 15 with value: 0.925.\n",
      "[I 2025-11-06 18:07:47,167] Trial 21 finished with value: 0.875 and parameters: {'max_depth': 11, 'eta': 0.1008227569664488, 'subsample': 0.7958358810454305, 'colsample_bytree': 0.5175257542315063, 'gamma': 0.6310661359303502, 'reg_alpha': 3.4633567177536086, 'reg_lambda': 4.06872359704784}. Best is trial 15 with value: 0.925.\n",
      "[I 2025-11-06 18:07:47,440] Trial 22 finished with value: 0.775 and parameters: {'max_depth': 11, 'eta': 0.11348734333753965, 'subsample': 0.7839116701841154, 'colsample_bytree': 0.5059364005148377, 'gamma': 3.05311052376479, 'reg_alpha': 3.751841880808982, 'reg_lambda': 4.261170043882152}. Best is trial 15 with value: 0.925.\n",
      "[I 2025-11-06 18:07:48,584] Trial 23 finished with value: 0.875 and parameters: {'max_depth': 11, 'eta': 0.13115503691263541, 'subsample': 0.799243273190922, 'colsample_bytree': 0.5173882376203289, 'gamma': 2.9678477469204743, 'reg_alpha': 0.537400682645728, 'reg_lambda': 4.275336972638554}. Best is trial 15 with value: 0.925.\n",
      "[I 2025-11-06 18:07:48,788] Trial 24 finished with value: 0.875 and parameters: {'max_depth': 11, 'eta': 0.13919382516892406, 'subsample': 0.8190638862295294, 'colsample_bytree': 0.505370411951671, 'gamma': 3.0512709027356024, 'reg_alpha': 0.49755055342402654, 'reg_lambda': 4.2693163319300504}. Best is trial 15 with value: 0.925.\n"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective2, n_trials=25, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = xgb.train({**study.best_trial.params,\n",
    "                 **default_params,}, dtrain, num_boost_round = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dtest\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UMAP reduction to 2D\n",
    "# umap_model = umap.UMAP(n_neighbors=10, min_dist=0.3, random_state=42, n_components=2)\n",
    "# emb_2d = umap_model.fit_transform(embeddings)\n",
    "\n",
    "# # Some Overlap is expected\n",
    "# #High-dimensional separation may not be visible in 2d\n",
    "# #Can try diff embedding/tokenizer\n",
    "\n",
    "\n",
    "# # Scatterplot\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# scatter = plt.scatter(emb_2d[:, 0], emb_2d[:, 1], c=labels, cmap=\"Spectral\", alpha=0.8)\n",
    "# plt.xlabel(\"UMAP-1\")\n",
    "# plt.ylabel(\"UMAP-2\")\n",
    "# plt.title(\"Sentence Embeddings with UMAP (colored by label)\")\n",
    "# plt.colorbar(scatter, label=\"Dependent Variable (0/1)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlb_embeddings = get_embeddings(df_unlb, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186469fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "thresh = 0.95\n",
    "\n",
    "\n",
    "optuna_params = study.best_trial.params\n",
    "\n",
    "X_c, y_c = X_train.clone(), y_train.clone()\n",
    "X_unlb = unlb_embeddings.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b6fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>Epoch 1<<<<\n",
      "Added 143 pseudo samples. Labeled samples size: 374\n",
      "\n",
      ">>>>Epoch 2<<<<\n",
      "Added 30 pseudo samples. Labeled samples size: 404\n",
      "\n",
      ">>>>Epoch 3<<<<\n",
      "Added 7 pseudo samples. Labeled samples size: 411\n",
      "\n",
      ">>>>Epoch 4<<<<\n",
      "Added 4 pseudo samples. Labeled samples size: 415\n",
      "\n",
      ">>>>Epoch 5<<<<\n",
      "Added 3 pseudo samples. Labeled samples size: 418\n",
      "\n",
      ">>>>Epoch 6<<<<\n",
      "Added 2 pseudo samples. Labeled samples size: 420\n",
      "\n",
      ">>>>Epoch 7<<<<\n",
      "Added 2 pseudo samples. Labeled samples size: 422\n",
      "\n",
      ">>>>Epoch 8<<<<\n",
      "Added 1 pseudo samples. Labeled samples size: 423\n",
      "\n",
      ">>>>Epoch 9<<<<\n",
      "Added 1 pseudo samples. Labeled samples size: 424\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,epochs):\n",
    "    print(f\"\\n>>>>Epoch {epoch}<<<<\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_c, label=y_c)\n",
    "    model = xgb.train({**optuna_params,\n",
    "                       **default_params}, dtrain, num_boost_round=1500)\n",
    "\n",
    "    if len(X_unlb) == 0:\n",
    "        print(\"No unlabeled data left.\")\n",
    "        break\n",
    "\n",
    "    d_unlb = xgb.DMatrix(X_unlb)\n",
    "    y_proba = model.predict(d_unlb)\n",
    "    y_proba = torch.from_numpy(y_proba).cuda()\n",
    "\n",
    "    mask = (y_proba > thresh) | (y_proba < 1 - thresh) # a tensor of True, False... of shape y_proba\n",
    "    \n",
    "    if mask.sum() == 0:                                # True==1, False==0\n",
    "        print(\"No high-confidence samples found.\")\n",
    "        break\n",
    "\n",
    "    X_pseudo = X_unlb[mask]\n",
    "    y_pseudo = (y_proba[mask] > 0.5).int() # torch.int\n",
    "\n",
    "    # move high confidence rows from unlabeled to training set\n",
    "    X_c = torch.vstack([X_c, X_pseudo]) # stacks vertically. similar to 1d append but for high d's. \n",
    "    y_c = torch.cat([y_c, y_pseudo], axis =0)\n",
    "\n",
    "    # Remove high confidence rows\n",
    "    X_unlb = X_unlb[~mask]\n",
    "\n",
    "    print(f\"Added {len(X_pseudo)} pseudo samples. Labeled samples size: {len(y_c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d55446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model\n",
    "dfinal = xgb.DMatrix(X_c, label=y_c)\n",
    "final_model = xgb.train({**optuna_params,\n",
    "                 **default_params,}, dfinal, num_boost_round = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d21fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  3]\n",
      " [ 3 37]]\n"
     ]
    }
   ],
   "source": [
    "dunlabeled = xgb.DMatrix(X_test)\n",
    "y_pred_proba = final_model.predict(dunlabeled)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "# Decrease threshold for negating False Negatives\n",
    "y_pred_binary = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm =confusion_matrix(y_test_np, y_pred_binary)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d664337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test_np, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save_model(\"data/XGBmodel.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cdca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = \"\"\n",
    "body = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7819592]\n"
     ]
    }
   ],
   "source": [
    "df_2 = pd.DataFrame({\n",
    "    \"Subject\": [sub],\n",
    "    \"Body\":[body]\n",
    "})\n",
    "\n",
    "embeddings_2 =get_embeddings(df_2, model_name)\n",
    "\n",
    "dunlabeled_2 = xgb.DMatrix(embeddings_2)\n",
    "y_pred_proba_2 = final_model.predict(dunlabeled_2)\n",
    "print(y_pred_proba_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xm= xgb.Booster()\n",
    "# xm.load_model(\"data/XGBmodel.json\")\n",
    "\n",
    "# config = xm.save_config()\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d70db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_date=datetime(2025,8,26)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow-docker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
